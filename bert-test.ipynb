{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/efreiparisdeeplearning2019/dataset_train.csv\n",
      "/kaggle/input/efreiparisdeeplearning2019/example_submission_test.csv\n",
      "/kaggle/input/efreiparisdeeplearning2019/dataset_test_no_labels.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## install transformers library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\r\n",
      "\u001b[K     |████████████████████████████████| 450kB 2.8MB/s \r\n",
      "\u001b[?25hCollecting sacremoses\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\r\n",
      "\u001b[K     |████████████████████████████████| 870kB 35.3MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (2019.11.1)\r\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.6/site-packages (from transformers) (1.10.29)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from transformers) (4.39.0)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (from transformers) (0.1.83)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers) (2.22.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from transformers) (1.17.4)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.13.0)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (7.0)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (0.14.0)\r\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3->transformers) (0.9.4)\r\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.29 in /opt/conda/lib/python3.6/site-packages (from boto3->transformers) (1.13.29)\r\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from boto3->transformers) (0.2.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2019.9.11)\r\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (1.24.2)\r\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2.8)\r\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /opt/conda/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.29->boto3->transformers) (2.8.0)\r\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.29->boto3->transformers) (0.15.2)\r\n",
      "Building wheels for collected packages: sacremoses\r\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884629 sha256=3cab7463637cf8b81a78239c23739c7dc3ac60fb74613380cf86414cb8a5136d\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\r\n",
      "Successfully built sacremoses\r\n",
      "Installing collected packages: sacremoses, transformers\r\n",
      "Successfully installed sacremoses-0.0.38 transformers-2.3.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports and activate GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "if torch.cuda.is_available():    \n",
    "  \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_1</th>\n",
       "      <th>sentence_2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Conceptually cream skimming has two basic dime...</td>\n",
       "      <td>Product and geography are what make cream skim...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you know during the season and i guess at at y...</td>\n",
       "      <td>You lose the things to the following level if ...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One of our number will carry out your instruct...</td>\n",
       "      <td>A member of my team will execute your orders w...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do you know? All this is their information...</td>\n",
       "      <td>This information belongs to them.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yeah i tell you what though if you go price so...</td>\n",
       "      <td>The tennis shoes have a range of prices.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence_1  \\\n",
       "index                                                      \n",
       "0      Conceptually cream skimming has two basic dime...   \n",
       "1      you know during the season and i guess at at y...   \n",
       "2      One of our number will carry out your instruct...   \n",
       "3      How do you know? All this is their information...   \n",
       "4      yeah i tell you what though if you go price so...   \n",
       "\n",
       "                                              sentence_2       label  \n",
       "index                                                                 \n",
       "0      Product and geography are what make cream skim...     neutral  \n",
       "1      You lose the things to the following level if ...  entailment  \n",
       "2      A member of my team will execute your orders w...  entailment  \n",
       "3                      This information belongs to them.  entailment  \n",
       "4               The tennis shoes have a range of prices.     neutral  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/kaggle/input/efreiparisdeeplearning2019/dataset_train.csv\", sep='\\t', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing for bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bert = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_1</th>\n",
       "      <th>sentence_2</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] Conceptually cream skimming has two basi...</td>\n",
       "      <td>Product and geography are what make cream skim...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[CLS] Conceptually cream skimming has two basi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] you know during the season and i guess a...</td>\n",
       "      <td>You lose the things to the following level if ...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>[CLS] you know during the season and i guess a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS] One of our number will carry out your in...</td>\n",
       "      <td>A member of my team will execute your orders w...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>[CLS] One of our number will carry out your in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS] How do you know? All this is their infor...</td>\n",
       "      <td>This information belongs to them. [SEP]</td>\n",
       "      <td>entailment</td>\n",
       "      <td>[CLS] How do you know? All this is their infor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS] yeah i tell you what though if you go pr...</td>\n",
       "      <td>The tennis shoes have a range of prices. [SEP]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[CLS] yeah i tell you what though if you go pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence_1  \\\n",
       "index                                                      \n",
       "0      [CLS] Conceptually cream skimming has two basi...   \n",
       "1      [CLS] you know during the season and i guess a...   \n",
       "2      [CLS] One of our number will carry out your in...   \n",
       "3      [CLS] How do you know? All this is their infor...   \n",
       "4      [CLS] yeah i tell you what though if you go pr...   \n",
       "\n",
       "                                              sentence_2       label  \\\n",
       "index                                                                  \n",
       "0      Product and geography are what make cream skim...     neutral   \n",
       "1      You lose the things to the following level if ...  entailment   \n",
       "2      A member of my team will execute your orders w...  entailment   \n",
       "3                This information belongs to them. [SEP]  entailment   \n",
       "4         The tennis shoes have a range of prices. [SEP]     neutral   \n",
       "\n",
       "                                                sentence  \n",
       "index                                                     \n",
       "0      [CLS] Conceptually cream skimming has two basi...  \n",
       "1      [CLS] you know during the season and i guess a...  \n",
       "2      [CLS] One of our number will carry out your in...  \n",
       "3      [CLS] How do you know? All this is their infor...  \n",
       "4      [CLS] yeah i tell you what though if you go pr...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bert['sentence_1']= data_bert.sentence_1.apply(lambda x: \"[CLS] \" + x.strip() + \" [SEP] \") \n",
    "data_bert['sentence_2'] = data_bert.sentence_2.apply(lambda x: x.strip() + \" [SEP]\")\n",
    "data_bert['sentence'] = data_bert.sentence_1 + data_bert.sentence_2\n",
    "\n",
    "data_bert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Conceptually cream skimming has two basic dimensions - product and geography.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sentence_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_ids = tokenizer.encode(data.sentence_1[0], text_pair=data.sentence_2[0], add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "392662it [09:49, 665.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# Prends environ 10 min\n",
    "input_ids = list()\n",
    "#tq = tqdm.tqdm()\n",
    "for sent1,sent2 in tqdm(zip(data.sentence_1,data.sentence_2)):\n",
    "    input_ids.append(tokenizer.encode(sent1, text_pair=sent2, add_special_tokens=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bert['input_ids']=input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_ids = data_bert.input_ids.apply(lambda x: [0] * (x.index(102)+1) + [1] * (len(x)-(x.index(102)+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean length of sentences : 39.9166407750177\n"
     ]
    }
   ],
   "source": [
    "print( \"mean length of sentences :\", sum(map(len,data_bert.input_ids))/len(data_bert.input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "# Pad input tokens\n",
    "input_ids = np.array(data_bert.input_ids)\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\",padding=\"post\")\n",
    "# Pad segment id\n",
    "segment_ids = np.array(segment_ids)\n",
    "segment_ids = pad_sequences(segment_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\",padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "# Create a mask : 1 if token else 0\n",
    "for seq in input_ids:\n",
    "    seq_mask = [int(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "classes = dict(zip(classes, range(len(classes))))\n",
    "data_bert[\"label_encoded\"] = data_bert.label.map(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(data_bert[\"label_encoded\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=44, test_size=0.1)\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
    "                                             random_state=44, test_size=0.1)\n",
    "train_segment_ids, validation_segment_ids, _, _ = train_test_split(segment_ids, labels,\n",
    "                                                             random_state=44,test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all inputs and labels into torch tensors\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "train_segment = torch.tensor(train_segment_ids)\n",
    "validation_segment = torch.tensor(validation_segment_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create batch / dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 32\n",
    "\n",
    "#DataLoader training \n",
    "train_data = TensorDataset(train_inputs, train_masks, train_segment ,train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "#DataLoader validation\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_segment,validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instanciate bert model & set it on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "#pretrained BERT model + single linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", #12-layer BERT model uncased vocab\n",
    "    num_labels = 3,  \n",
    "    output_attentions = False, \n",
    "    output_hidden_states = False, \n",
    ")\n",
    "\n",
    "# pytorch GPU\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print model parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (3, 768)\n",
      "classifier.bias                                                 (3,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'W' stands for 'Weight Decay fix\" maybe\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 1e-5, \n",
    "                  eps = 1e-8\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define epoch, step & scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# between 2 and 4 epoch is good\n",
    "epochs = 2\n",
    "\n",
    "# number of batches * number of epochs\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "#learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to get flatten result + accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to format time (only for display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "  Batch   100  of  11,044.    Elapsed: 0:00:43.  Loss: 0.9145575165748596\n",
      "  Batch   200  of  11,044.    Elapsed: 0:01:26.  Loss: 0.8829405903816223\n",
      "  Batch   300  of  11,044.    Elapsed: 0:02:08.  Loss: 0.677834153175354\n",
      "  Batch   400  of  11,044.    Elapsed: 0:02:50.  Loss: 0.6953713297843933\n",
      "  Batch   500  of  11,044.    Elapsed: 0:03:32.  Loss: 0.8736481070518494\n",
      "  Batch   600  of  11,044.    Elapsed: 0:04:14.  Loss: 0.5869234800338745\n",
      "  Batch   700  of  11,044.    Elapsed: 0:04:57.  Loss: 0.605618417263031\n",
      "  Batch   800  of  11,044.    Elapsed: 0:05:39.  Loss: 1.1697375774383545\n",
      "  Batch   900  of  11,044.    Elapsed: 0:06:21.  Loss: 0.8868364095687866\n",
      "  Batch 1,000  of  11,044.    Elapsed: 0:07:04.  Loss: 0.7421754002571106\n",
      "  Batch 1,100  of  11,044.    Elapsed: 0:07:46.  Loss: 0.5806711912155151\n",
      "  Batch 1,200  of  11,044.    Elapsed: 0:08:28.  Loss: 0.5876591801643372\n",
      "  Batch 1,300  of  11,044.    Elapsed: 0:09:11.  Loss: 0.6066928505897522\n",
      "  Batch 1,400  of  11,044.    Elapsed: 0:09:53.  Loss: 0.678135335445404\n",
      "  Batch 1,500  of  11,044.    Elapsed: 0:10:35.  Loss: 0.5922245979309082\n",
      "  Batch 1,600  of  11,044.    Elapsed: 0:11:18.  Loss: 0.452480286359787\n",
      "  Batch 1,700  of  11,044.    Elapsed: 0:12:00.  Loss: 0.8749942779541016\n",
      "  Batch 1,800  of  11,044.    Elapsed: 0:12:42.  Loss: 0.6626993417739868\n",
      "  Batch 1,900  of  11,044.    Elapsed: 0:13:24.  Loss: 0.3732939064502716\n",
      "  Batch 2,000  of  11,044.    Elapsed: 0:14:06.  Loss: 0.578433096408844\n",
      "  Batch 2,100  of  11,044.    Elapsed: 0:14:49.  Loss: 0.5205380320549011\n",
      "  Batch 2,200  of  11,044.    Elapsed: 0:15:31.  Loss: 0.7317128777503967\n",
      "  Batch 2,300  of  11,044.    Elapsed: 0:16:13.  Loss: 0.5249984264373779\n",
      "  Batch 2,400  of  11,044.    Elapsed: 0:16:55.  Loss: 0.5160797238349915\n",
      "  Batch 2,500  of  11,044.    Elapsed: 0:17:38.  Loss: 0.4708944261074066\n",
      "  Batch 2,600  of  11,044.    Elapsed: 0:18:20.  Loss: 0.605676531791687\n",
      "  Batch 2,700  of  11,044.    Elapsed: 0:19:02.  Loss: 0.5150927305221558\n",
      "  Batch 2,800  of  11,044.    Elapsed: 0:19:44.  Loss: 0.7630977630615234\n",
      "  Batch 2,900  of  11,044.    Elapsed: 0:20:27.  Loss: 0.4854458272457123\n",
      "  Batch 3,000  of  11,044.    Elapsed: 0:21:09.  Loss: 0.5059784054756165\n",
      "  Batch 3,100  of  11,044.    Elapsed: 0:21:51.  Loss: 0.8065698146820068\n",
      "  Batch 3,200  of  11,044.    Elapsed: 0:22:33.  Loss: 0.5152526497840881\n",
      "  Batch 3,300  of  11,044.    Elapsed: 0:23:16.  Loss: 0.5975015163421631\n",
      "  Batch 3,400  of  11,044.    Elapsed: 0:23:58.  Loss: 0.4834243655204773\n",
      "  Batch 3,500  of  11,044.    Elapsed: 0:24:40.  Loss: 0.8582959175109863\n",
      "  Batch 3,600  of  11,044.    Elapsed: 0:25:23.  Loss: 0.6741278767585754\n",
      "  Batch 3,700  of  11,044.    Elapsed: 0:26:05.  Loss: 0.5148983597755432\n",
      "  Batch 3,800  of  11,044.    Elapsed: 0:26:47.  Loss: 0.4790341854095459\n",
      "  Batch 3,900  of  11,044.    Elapsed: 0:27:29.  Loss: 0.4087763726711273\n",
      "  Batch 4,000  of  11,044.    Elapsed: 0:28:11.  Loss: 0.49369609355926514\n",
      "  Batch 4,100  of  11,044.    Elapsed: 0:28:53.  Loss: 0.478791207075119\n",
      "  Batch 4,200  of  11,044.    Elapsed: 0:29:36.  Loss: 0.3973134160041809\n",
      "  Batch 4,300  of  11,044.    Elapsed: 0:30:18.  Loss: 0.4121741056442261\n",
      "  Batch 4,400  of  11,044.    Elapsed: 0:31:00.  Loss: 0.7029635310173035\n",
      "  Batch 4,500  of  11,044.    Elapsed: 0:31:42.  Loss: 0.6520491242408752\n",
      "  Batch 4,600  of  11,044.    Elapsed: 0:32:25.  Loss: 0.3556802272796631\n",
      "  Batch 4,700  of  11,044.    Elapsed: 0:33:07.  Loss: 0.3300060033798218\n",
      "  Batch 4,800  of  11,044.    Elapsed: 0:33:49.  Loss: 0.6504132151603699\n",
      "  Batch 4,900  of  11,044.    Elapsed: 0:34:31.  Loss: 0.5349454283714294\n",
      "  Batch 5,000  of  11,044.    Elapsed: 0:35:13.  Loss: 0.4648074805736542\n",
      "  Batch 5,100  of  11,044.    Elapsed: 0:35:56.  Loss: 0.7782199382781982\n",
      "  Batch 5,200  of  11,044.    Elapsed: 0:36:38.  Loss: 0.4595901072025299\n",
      "  Batch 5,300  of  11,044.    Elapsed: 0:37:20.  Loss: 0.49582868814468384\n",
      "  Batch 5,400  of  11,044.    Elapsed: 0:38:02.  Loss: 0.5020720362663269\n",
      "  Batch 5,500  of  11,044.    Elapsed: 0:38:44.  Loss: 0.5530133247375488\n",
      "  Batch 5,600  of  11,044.    Elapsed: 0:39:26.  Loss: 0.5879697799682617\n",
      "  Batch 5,700  of  11,044.    Elapsed: 0:40:09.  Loss: 0.46482521295547485\n",
      "  Batch 5,800  of  11,044.    Elapsed: 0:40:51.  Loss: 0.5124626159667969\n",
      "  Batch 5,900  of  11,044.    Elapsed: 0:41:33.  Loss: 0.3834093511104584\n",
      "  Batch 6,000  of  11,044.    Elapsed: 0:42:15.  Loss: 0.330072820186615\n",
      "  Batch 6,100  of  11,044.    Elapsed: 0:42:57.  Loss: 0.5614993572235107\n",
      "  Batch 6,200  of  11,044.    Elapsed: 0:43:40.  Loss: 0.7592424750328064\n",
      "  Batch 6,300  of  11,044.    Elapsed: 0:44:22.  Loss: 0.4673719108104706\n",
      "  Batch 6,400  of  11,044.    Elapsed: 0:45:04.  Loss: 0.6619174480438232\n",
      "  Batch 6,500  of  11,044.    Elapsed: 0:45:46.  Loss: 0.49886515736579895\n",
      "  Batch 6,600  of  11,044.    Elapsed: 0:46:28.  Loss: 0.7260886430740356\n",
      "  Batch 6,700  of  11,044.    Elapsed: 0:47:10.  Loss: 0.6534428000450134\n",
      "  Batch 6,800  of  11,044.    Elapsed: 0:47:52.  Loss: 0.26357144117355347\n",
      "  Batch 6,900  of  11,044.    Elapsed: 0:48:35.  Loss: 0.4377745985984802\n",
      "  Batch 7,000  of  11,044.    Elapsed: 0:49:17.  Loss: 0.3929162621498108\n",
      "  Batch 7,100  of  11,044.    Elapsed: 0:49:59.  Loss: 0.7045732736587524\n",
      "  Batch 7,200  of  11,044.    Elapsed: 0:50:41.  Loss: 0.5415486097335815\n",
      "  Batch 7,300  of  11,044.    Elapsed: 0:51:23.  Loss: 0.785031259059906\n",
      "  Batch 7,400  of  11,044.    Elapsed: 0:52:05.  Loss: 0.4743626117706299\n",
      "  Batch 7,500  of  11,044.    Elapsed: 0:52:47.  Loss: 0.4507858157157898\n",
      "  Batch 7,600  of  11,044.    Elapsed: 0:53:30.  Loss: 0.5231806635856628\n",
      "  Batch 7,700  of  11,044.    Elapsed: 0:54:12.  Loss: 0.6980249285697937\n",
      "  Batch 7,800  of  11,044.    Elapsed: 0:54:54.  Loss: 0.2787618339061737\n",
      "  Batch 7,900  of  11,044.    Elapsed: 0:55:36.  Loss: 0.6605890989303589\n",
      "  Batch 8,000  of  11,044.    Elapsed: 0:56:19.  Loss: 0.6405271291732788\n",
      "  Batch 8,100  of  11,044.    Elapsed: 0:57:01.  Loss: 0.7580105066299438\n",
      "  Batch 8,200  of  11,044.    Elapsed: 0:57:43.  Loss: 0.3943597674369812\n",
      "  Batch 8,300  of  11,044.    Elapsed: 0:58:25.  Loss: 0.5178914070129395\n",
      "  Batch 8,400  of  11,044.    Elapsed: 0:59:07.  Loss: 0.2782035768032074\n",
      "  Batch 8,500  of  11,044.    Elapsed: 0:59:49.  Loss: 0.36326783895492554\n",
      "  Batch 8,600  of  11,044.    Elapsed: 1:00:32.  Loss: 0.3726668357849121\n",
      "  Batch 8,700  of  11,044.    Elapsed: 1:01:14.  Loss: 0.31466594338417053\n",
      "  Batch 8,800  of  11,044.    Elapsed: 1:01:56.  Loss: 0.4314076602458954\n",
      "  Batch 8,900  of  11,044.    Elapsed: 1:02:38.  Loss: 0.6177999377250671\n",
      "  Batch 9,000  of  11,044.    Elapsed: 1:03:20.  Loss: 0.36845284700393677\n",
      "  Batch 9,100  of  11,044.    Elapsed: 1:04:02.  Loss: 0.5650089979171753\n",
      "  Batch 9,200  of  11,044.    Elapsed: 1:04:45.  Loss: 0.3417492210865021\n",
      "  Batch 9,300  of  11,044.    Elapsed: 1:05:27.  Loss: 0.4840291440486908\n",
      "  Batch 9,400  of  11,044.    Elapsed: 1:06:09.  Loss: 0.632595419883728\n",
      "  Batch 9,500  of  11,044.    Elapsed: 1:06:51.  Loss: 0.8018739819526672\n",
      "  Batch 9,600  of  11,044.    Elapsed: 1:07:33.  Loss: 0.5456278920173645\n",
      "  Batch 9,700  of  11,044.    Elapsed: 1:08:15.  Loss: 0.27671271562576294\n",
      "  Batch 9,800  of  11,044.    Elapsed: 1:08:57.  Loss: 0.585606575012207\n",
      "  Batch 9,900  of  11,044.    Elapsed: 1:09:40.  Loss: 0.38023969531059265\n",
      "  Batch 10,000  of  11,044.    Elapsed: 1:10:22.  Loss: 0.45284655690193176\n",
      "  Batch 10,100  of  11,044.    Elapsed: 1:11:04.  Loss: 0.749427318572998\n",
      "  Batch 10,200  of  11,044.    Elapsed: 1:11:46.  Loss: 0.43407949805259705\n",
      "  Batch 10,300  of  11,044.    Elapsed: 1:12:28.  Loss: 0.5586147308349609\n",
      "  Batch 10,400  of  11,044.    Elapsed: 1:13:10.  Loss: 0.42581093311309814\n",
      "  Batch 10,500  of  11,044.    Elapsed: 1:13:52.  Loss: 0.5650673508644104\n",
      "  Batch 10,600  of  11,044.    Elapsed: 1:14:35.  Loss: 0.33337652683258057\n",
      "  Batch 10,700  of  11,044.    Elapsed: 1:15:17.  Loss: 0.4766099154949188\n",
      "  Batch 10,800  of  11,044.    Elapsed: 1:15:59.  Loss: 0.3363052308559418\n",
      "  Batch 10,900  of  11,044.    Elapsed: 1:16:41.  Loss: 0.682059109210968\n",
      "  Batch 11,000  of  11,044.    Elapsed: 1:17:24.  Loss: 0.47671744227409363\n",
      "\n",
      "  Average training loss: 0.55\n",
      "  Training epoch took: 1:17:42\n",
      "Running Validation...\n",
      "  Accuracy: 0.82\n",
      "  Validation took: 0:02:38\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "  Batch   100  of  11,044.    Elapsed: 0:00:42.  Loss: 0.27150940895080566\n",
      "  Batch   200  of  11,044.    Elapsed: 0:01:24.  Loss: 0.39001139998435974\n",
      "  Batch   300  of  11,044.    Elapsed: 0:02:07.  Loss: 0.43215498328208923\n",
      "  Batch   400  of  11,044.    Elapsed: 0:02:49.  Loss: 0.5331672430038452\n",
      "  Batch   500  of  11,044.    Elapsed: 0:03:31.  Loss: 0.3820037841796875\n",
      "  Batch   600  of  11,044.    Elapsed: 0:04:13.  Loss: 0.27982908487319946\n",
      "  Batch   700  of  11,044.    Elapsed: 0:04:55.  Loss: 0.2466343343257904\n",
      "  Batch   800  of  11,044.    Elapsed: 0:05:37.  Loss: 0.6221827268600464\n",
      "  Batch   900  of  11,044.    Elapsed: 0:06:20.  Loss: 0.5567954182624817\n",
      "  Batch 1,000  of  11,044.    Elapsed: 0:07:02.  Loss: 0.43306538462638855\n",
      "  Batch 1,100  of  11,044.    Elapsed: 0:07:44.  Loss: 0.4595908522605896\n",
      "  Batch 1,200  of  11,044.    Elapsed: 0:08:26.  Loss: 0.426741361618042\n",
      "  Batch 1,300  of  11,044.    Elapsed: 0:09:08.  Loss: 0.33019784092903137\n",
      "  Batch 1,400  of  11,044.    Elapsed: 0:09:50.  Loss: 0.4659407138824463\n",
      "  Batch 1,500  of  11,044.    Elapsed: 0:10:32.  Loss: 0.415671169757843\n",
      "  Batch 1,600  of  11,044.    Elapsed: 0:11:15.  Loss: 0.5714395642280579\n",
      "  Batch 1,700  of  11,044.    Elapsed: 0:11:56.  Loss: 0.3668932020664215\n",
      "  Batch 1,800  of  11,044.    Elapsed: 0:12:39.  Loss: 0.22164271771907806\n",
      "  Batch 1,900  of  11,044.    Elapsed: 0:13:21.  Loss: 0.44029441475868225\n",
      "  Batch 2,000  of  11,044.    Elapsed: 0:14:03.  Loss: 0.29530060291290283\n",
      "  Batch 2,100  of  11,044.    Elapsed: 0:14:45.  Loss: 0.41139906644821167\n",
      "  Batch 2,200  of  11,044.    Elapsed: 0:15:27.  Loss: 0.5642809867858887\n",
      "  Batch 2,300  of  11,044.    Elapsed: 0:16:09.  Loss: 0.40767064690589905\n",
      "  Batch 2,400  of  11,044.    Elapsed: 0:16:51.  Loss: 0.5651256442070007\n",
      "  Batch 2,500  of  11,044.    Elapsed: 0:17:34.  Loss: 0.4387783110141754\n",
      "  Batch 2,600  of  11,044.    Elapsed: 0:18:16.  Loss: 0.3501254618167877\n",
      "  Batch 2,700  of  11,044.    Elapsed: 0:18:58.  Loss: 0.28004390001296997\n",
      "  Batch 2,800  of  11,044.    Elapsed: 0:19:40.  Loss: 0.25411322712898254\n",
      "  Batch 2,900  of  11,044.    Elapsed: 0:20:22.  Loss: 0.4689859449863434\n",
      "  Batch 3,000  of  11,044.    Elapsed: 0:21:04.  Loss: 0.2499057501554489\n",
      "  Batch 3,100  of  11,044.    Elapsed: 0:21:46.  Loss: 0.42140111327171326\n",
      "  Batch 3,200  of  11,044.    Elapsed: 0:22:29.  Loss: 0.4662271738052368\n",
      "  Batch 3,300  of  11,044.    Elapsed: 0:23:11.  Loss: 0.7233195900917053\n",
      "  Batch 3,400  of  11,044.    Elapsed: 0:23:53.  Loss: 0.4300345778465271\n",
      "  Batch 3,500  of  11,044.    Elapsed: 0:24:35.  Loss: 0.41804665327072144\n",
      "  Batch 3,600  of  11,044.    Elapsed: 0:25:17.  Loss: 0.33036553859710693\n",
      "  Batch 3,700  of  11,044.    Elapsed: 0:25:59.  Loss: 0.2196788191795349\n",
      "  Batch 3,800  of  11,044.    Elapsed: 0:26:41.  Loss: 0.6132529377937317\n",
      "  Batch 3,900  of  11,044.    Elapsed: 0:27:23.  Loss: 0.3560776114463806\n",
      "  Batch 4,000  of  11,044.    Elapsed: 0:28:06.  Loss: 0.24460214376449585\n",
      "  Batch 4,100  of  11,044.    Elapsed: 0:28:48.  Loss: 0.32670775055885315\n",
      "  Batch 4,200  of  11,044.    Elapsed: 0:29:30.  Loss: 0.37847477197647095\n",
      "  Batch 4,300  of  11,044.    Elapsed: 0:30:12.  Loss: 0.5032210946083069\n",
      "  Batch 4,400  of  11,044.    Elapsed: 0:30:54.  Loss: 0.34387657046318054\n",
      "  Batch 4,500  of  11,044.    Elapsed: 0:31:36.  Loss: 0.18140561878681183\n",
      "  Batch 4,600  of  11,044.    Elapsed: 0:32:18.  Loss: 0.30313557386398315\n",
      "  Batch 4,700  of  11,044.    Elapsed: 0:33:01.  Loss: 0.571599543094635\n",
      "  Batch 4,800  of  11,044.    Elapsed: 0:33:43.  Loss: 0.5120317935943604\n",
      "  Batch 4,900  of  11,044.    Elapsed: 0:34:25.  Loss: 0.3514968156814575\n",
      "  Batch 5,000  of  11,044.    Elapsed: 0:35:07.  Loss: 0.41379454731941223\n",
      "  Batch 5,100  of  11,044.    Elapsed: 0:35:49.  Loss: 0.5304553508758545\n",
      "  Batch 5,200  of  11,044.    Elapsed: 0:36:31.  Loss: 0.3381497859954834\n",
      "  Batch 5,300  of  11,044.    Elapsed: 0:37:13.  Loss: 0.30681461095809937\n",
      "  Batch 5,400  of  11,044.    Elapsed: 0:37:55.  Loss: 0.33577367663383484\n",
      "  Batch 5,500  of  11,044.    Elapsed: 0:38:38.  Loss: 0.40617841482162476\n",
      "  Batch 5,600  of  11,044.    Elapsed: 0:39:20.  Loss: 0.6473150253295898\n",
      "  Batch 5,700  of  11,044.    Elapsed: 0:40:02.  Loss: 0.37521764636039734\n",
      "  Batch 5,800  of  11,044.    Elapsed: 0:40:44.  Loss: 0.2272917926311493\n",
      "  Batch 5,900  of  11,044.    Elapsed: 0:41:26.  Loss: 0.39605388045310974\n",
      "  Batch 6,000  of  11,044.    Elapsed: 0:42:08.  Loss: 0.3507642149925232\n",
      "  Batch 6,100  of  11,044.    Elapsed: 0:42:50.  Loss: 0.36709704995155334\n",
      "  Batch 6,200  of  11,044.    Elapsed: 0:43:32.  Loss: 0.4368758797645569\n",
      "  Batch 6,300  of  11,044.    Elapsed: 0:44:15.  Loss: 0.44940534234046936\n",
      "  Batch 6,400  of  11,044.    Elapsed: 0:44:57.  Loss: 0.2799921929836273\n",
      "  Batch 6,500  of  11,044.    Elapsed: 0:45:39.  Loss: 0.402831494808197\n",
      "  Batch 6,600  of  11,044.    Elapsed: 0:46:21.  Loss: 0.3944868743419647\n",
      "  Batch 6,700  of  11,044.    Elapsed: 0:47:03.  Loss: 0.33720406889915466\n",
      "  Batch 6,800  of  11,044.    Elapsed: 0:47:45.  Loss: 0.26882028579711914\n",
      "  Batch 6,900  of  11,044.    Elapsed: 0:48:28.  Loss: 0.4319649934768677\n",
      "  Batch 7,000  of  11,044.    Elapsed: 0:49:10.  Loss: 0.49945300817489624\n",
      "  Batch 7,100  of  11,044.    Elapsed: 0:49:52.  Loss: 0.35321009159088135\n",
      "  Batch 7,200  of  11,044.    Elapsed: 0:50:34.  Loss: 0.4311387538909912\n",
      "  Batch 7,300  of  11,044.    Elapsed: 0:51:16.  Loss: 0.1836787462234497\n",
      "  Batch 7,400  of  11,044.    Elapsed: 0:51:58.  Loss: 0.2593953013420105\n",
      "  Batch 7,500  of  11,044.    Elapsed: 0:52:40.  Loss: 0.46550220251083374\n",
      "  Batch 7,600  of  11,044.    Elapsed: 0:53:22.  Loss: 0.47436943650245667\n",
      "  Batch 7,700  of  11,044.    Elapsed: 0:54:05.  Loss: 0.2814140021800995\n",
      "  Batch 7,800  of  11,044.    Elapsed: 0:54:47.  Loss: 0.5492825508117676\n",
      "  Batch 7,900  of  11,044.    Elapsed: 0:55:29.  Loss: 0.3999524414539337\n",
      "  Batch 8,000  of  11,044.    Elapsed: 0:56:11.  Loss: 0.4812794327735901\n",
      "  Batch 8,100  of  11,044.    Elapsed: 0:56:53.  Loss: 0.5044089555740356\n",
      "  Batch 8,200  of  11,044.    Elapsed: 0:57:36.  Loss: 0.31956207752227783\n",
      "  Batch 8,300  of  11,044.    Elapsed: 0:58:18.  Loss: 0.4144890606403351\n",
      "  Batch 8,400  of  11,044.    Elapsed: 0:59:00.  Loss: 0.2811250686645508\n",
      "  Batch 8,500  of  11,044.    Elapsed: 0:59:42.  Loss: 0.392351895570755\n",
      "  Batch 8,600  of  11,044.    Elapsed: 1:00:24.  Loss: 0.31748083233833313\n",
      "  Batch 8,700  of  11,044.    Elapsed: 1:01:06.  Loss: 0.3143916130065918\n",
      "  Batch 8,800  of  11,044.    Elapsed: 1:01:48.  Loss: 0.16165629029273987\n",
      "  Batch 8,900  of  11,044.    Elapsed: 1:02:30.  Loss: 0.4527452886104584\n",
      "  Batch 9,000  of  11,044.    Elapsed: 1:03:12.  Loss: 0.2677135765552521\n",
      "  Batch 9,100  of  11,044.    Elapsed: 1:03:54.  Loss: 0.3188037872314453\n",
      "  Batch 9,200  of  11,044.    Elapsed: 1:04:37.  Loss: 0.4340839982032776\n",
      "  Batch 9,300  of  11,044.    Elapsed: 1:05:19.  Loss: 0.42848366498947144\n",
      "  Batch 9,400  of  11,044.    Elapsed: 1:06:01.  Loss: 0.5106525421142578\n",
      "  Batch 9,500  of  11,044.    Elapsed: 1:06:43.  Loss: 0.485355406999588\n",
      "  Batch 9,600  of  11,044.    Elapsed: 1:07:25.  Loss: 0.5008177757263184\n",
      "  Batch 9,700  of  11,044.    Elapsed: 1:08:07.  Loss: 0.6340206861495972\n",
      "  Batch 9,800  of  11,044.    Elapsed: 1:08:49.  Loss: 0.36651790142059326\n",
      "  Batch 9,900  of  11,044.    Elapsed: 1:09:31.  Loss: 0.2718973755836487\n",
      "  Batch 10,000  of  11,044.    Elapsed: 1:10:13.  Loss: 0.5559474229812622\n",
      "  Batch 10,100  of  11,044.    Elapsed: 1:10:55.  Loss: 0.24896126985549927\n",
      "  Batch 10,200  of  11,044.    Elapsed: 1:11:38.  Loss: 0.3243069052696228\n",
      "  Batch 10,300  of  11,044.    Elapsed: 1:12:20.  Loss: 0.36815163493156433\n",
      "  Batch 10,400  of  11,044.    Elapsed: 1:13:02.  Loss: 0.4149426221847534\n",
      "  Batch 10,500  of  11,044.    Elapsed: 1:13:44.  Loss: 0.48434051871299744\n",
      "  Batch 10,600  of  11,044.    Elapsed: 1:14:26.  Loss: 0.15941765904426575\n",
      "  Batch 10,700  of  11,044.    Elapsed: 1:15:08.  Loss: 0.23369622230529785\n",
      "  Batch 10,800  of  11,044.    Elapsed: 1:15:50.  Loss: 0.4638403058052063\n",
      "  Batch 10,900  of  11,044.    Elapsed: 1:16:32.  Loss: 0.24726100265979767\n",
      "  Batch 11,000  of  11,044.    Elapsed: 1:17:14.  Loss: 0.3325052857398987\n",
      "\n",
      "  Average training loss: 0.40\n",
      "  Training epoch took: 1:17:33\n",
      "Running Validation...\n",
      "  Accuracy: 0.83\n",
      "  Validation took: 0:02:38\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 44\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "loss_values = []\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    #  Training\n",
    "    print('\\n======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # training epoch time\n",
    "    t0 = time.time()\n",
    "\n",
    "    # reset loss for epoch\n",
    "    total_loss = 0\n",
    "\n",
    "    # model in training mode\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 100 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.  Loss: {:}'.format(step, len(train_dataloader), elapsed, loss.item()))\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_segment_ids = batch[2].to(device)\n",
    "        b_labels = batch[3].to(device)\n",
    "\n",
    "        # https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # return loss\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=b_segment_ids, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # all model return tuple -> tuple[0] is loss\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches \n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "\n",
    "    print(\"\\n  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "\n",
    "    #----------------Validation-----------------\n",
    "\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_segment_ids, b_labels = batch\n",
    "        \n",
    "        # Telling the model not to compute or store gradients, saving memory and\n",
    "        # speeding up validation\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            #---------PEUT ETRE CHANGER TOKEN_TYPE_IDS ????? ---------------------------\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=b_segment_ids, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "        # values prior to applying an activation function like the softmax.\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # accuracy of batch test\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # total accuracy\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # final accuracy \n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation\n",
    "df = pd.read_csv(\"/kaggle/input/efreiparisdeeplearning2019/dataset_test_no_labels.csv\", delimiter='\\t', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_1</th>\n",
       "      <th>sentence_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sentence_1, sentence_2]\n",
       "Index: []"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['sentence_2']==None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test sentences: 19647\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19647it [00:28, 699.09it/s]\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of test sentences: {df.shape[0]}\\n')\n",
    "\n",
    "input_ids = list()\n",
    "for sent1,sent2 in tqdm(zip(df.sentence_1,df.sentence_2)):\n",
    "    input_ids.append(tokenizer.encode(sent1, text_pair=sent2, add_special_tokens=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_ids']=input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_ids = df.input_ids.apply(lambda x: [0] * (x.index(102)+1) + [1] * (len(x)-(x.index(102)+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
    "                          dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_ids = np.array(segment_ids)\n",
    "segment_ids = pad_sequences(segment_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\",padding=\"post\")\n",
    "\n",
    "attention_masks = []\n",
    "for seq in input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "prediction_segment = torch.tensor(segment_ids)\n",
    "prediction_labels = None\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_segment)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 19647 test sentences...\n",
      "\tDONE.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicting labels for {len(prediction_inputs)} test sentences...\")\n",
    "model.eval()\n",
    "predictions = []\n",
    "for batch in prediction_dataloader:\n",
    "\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  b_input_ids, b_input_mask, b_segment_ids = batch\n",
    "\n",
    "  with torch.no_grad():\n",
    "      outputs = model(b_input_ids, token_type_ids=b_segment_ids, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  predictions.append(logits)\n",
    "\n",
    "print('\\tDONE.')\n",
    "flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flat prediction for human understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the predictions for each batch into a single list of 0,1,2.\n",
    "flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 2, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(flat_true_labels == flat_predictions).sum()/len(flat_true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report final result in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_classes = {v: k for k, v in classes.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'entailment', 1: 'neutral', 2: 'contradiction'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = pd.DataFrame(flat_predictions).reset_index().rename(columns={0:\"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result.label = final_result.label.map(inv_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index          label\n",
       "0      0     entailment\n",
       "1      1     entailment\n",
       "2      2     entailment\n",
       "3      3        neutral\n",
       "4      4     entailment\n",
       "5      5  contradiction\n",
       "6      6     entailment\n",
       "7      7  contradiction\n",
       "8      8        neutral\n",
       "9      9  contradiction"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL IN ONE CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertForSequenceClassification,BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "\n",
    "class bertTwoSentenceBertClassification:\n",
    "\n",
    "    def __init__(self, dataframe):\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda\")\n",
    "            print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "            print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "        else:\n",
    "            print('No GPU available, using the CPU instead.')\n",
    "            self.device = torch.device(\"cpu\")\n",
    "\n",
    "        self.rawdata = dataframe\n",
    "        assert \"label\" in self.rawdata.columns.to_list() and \"sentence_1\" in self.rawdata.columns.to_list() and \\\n",
    "               \"sentence_2\" in self.rawdata.columns.to_list(), \\\n",
    "            \"Dataframe should contain columns ['sentence_1','sentence_2','label']\"\n",
    "        self.tokenizer = None\n",
    "        self.input_ids, self.segment_ids, self.attention_mask = None, None, None\n",
    "        self.labels, self.classes = None, None\n",
    "        self.train_inputs, self.validation_inputs = None, None\n",
    "        self.train_labels, self.validation_labels = None, None\n",
    "        self.train_masks, self.validation_masks = None, None\n",
    "        self.train_segment, self.validation_segment = None, None\n",
    "        self.train_dataloader, self.validation_dataloader = None, None\n",
    "        self.model, self.optimizer = None, None\n",
    "        self.epochs, self.total_steps, self.scheduler = None, None, None\n",
    "        self.flat_predictions = None\n",
    "\n",
    "        self.preprocessData()\n",
    "        self.encode_class()\n",
    "        self.train_test_tensor()\n",
    "        self.create_batch()\n",
    "        self.instanciate_bert()\n",
    "        self.train_model()\n",
    "\n",
    "    def preprocessData(self, model='bert-base-uncased', do_lower_case=True):\n",
    "\n",
    "        def get_input_ids(tokenizer):\n",
    "            input_ids = list()\n",
    "            print(f\"Converting {len(self.rawdata.sentence_1)} to bert ids...\")\n",
    "            for sent1, sent2 in tqdm(zip(self.rawdata.sentence_1, self.rawdata.sentence_2)):\n",
    "                input_ids.append(tokenizer.encode(sent1, text_pair=sent2, add_special_tokens=True))\n",
    "            return input_ids\n",
    "\n",
    "        def get_padding(input_ids, segment_ids, max_len=128):\n",
    "            # Pad input tokens\n",
    "            input_ids = np.array(input_ids)\n",
    "            input_ids = pad_sequences(input_ids, maxlen=max_len, dtype=\"long\", value=0, truncating=\"post\",\n",
    "                                      padding=\"post\")\n",
    "            # Pad segment id\n",
    "            segment_ids = np.array(segment_ids)\n",
    "            segment_ids = pad_sequences(segment_ids, maxlen=max_len, dtype=\"long\", value=0, truncating=\"post\",\n",
    "                                        padding=\"post\")\n",
    "            return input_ids, segment_ids\n",
    "\n",
    "        def get_attention_mask(input_ids):\n",
    "            attention_masks = []\n",
    "            # Create a mask : 1 if token else 0\n",
    "            for seq in input_ids:\n",
    "                seq_mask = [int(i > 0) for i in seq]\n",
    "                attention_masks.append(seq_mask)\n",
    "            return attention_masks\n",
    "\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model, do_lower_case=do_lower_case)\n",
    "        self.input_ids = get_input_ids(self.tokenizer)\n",
    "        self.rawdata['input_ids'] = self.input_ids\n",
    "        self.rawdata['segment_ids'] = self.rawdata.input_ids.apply(\n",
    "            lambda x: [0] * (x.index(102) + 1) + [1] * (len(x) - (x.index(102) + 1)))\n",
    "        self.input_ids, self.segment_ids = get_padding(self.rawdata.input_ids, self.rawdata.segment_ids)\n",
    "        self.attention_mask = get_attention_mask(self.input_ids)\n",
    "\n",
    "    def encode_class(self):\n",
    "        classes = self.rawdata.label.unique().tolist()\n",
    "        self.classes = dict(zip(classes, range(len(classes))))\n",
    "        self.rawdata[\"label_encoded\"] = self.rawdata.label.map(self.classes)\n",
    "        self.labels = np.array(self.rawdata[\"label_encoded\"])\n",
    "\n",
    "    def train_test_tensor(self, random_state=44, split_size=0.1):\n",
    "        train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(self.input_ids, self.labels,\n",
    "                                                                                            random_state=random_state,\n",
    "                                                                                            test_size=split_size)\n",
    "        train_masks, validation_masks, _, _ = train_test_split(self.attention_mask, self.labels,\n",
    "                                                               random_state=random_state, test_size=split_size)\n",
    "        train_segment_ids, validation_segment_ids, _, _ = train_test_split(self.segment_ids, self.labels,\n",
    "                                                                           random_state=random_state,\n",
    "                                                                           test_size=split_size)\n",
    "        self.train_inputs = torch.tensor(train_inputs) # dtype=torch.long if running on windows\n",
    "        self.validation_inputs = torch.tensor(validation_inputs)\n",
    "\n",
    "        self.train_labels = torch.tensor(train_labels)\n",
    "        self.validation_labels = torch.tensor(validation_labels)\n",
    "\n",
    "        self.train_masks = torch.tensor(train_masks)\n",
    "        self.validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "        self.train_segment = torch.tensor(train_segment_ids)\n",
    "        self.validation_segment = torch.tensor(validation_segment_ids)\n",
    "\n",
    "    def create_batch(self, batch_size=32):\n",
    "        # For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32.\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # DataLoader training\n",
    "        train_data = TensorDataset(self.train_inputs, self.train_masks, self.train_segment, self.train_labels)\n",
    "        train_sampler = RandomSampler(train_data)\n",
    "        self.train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "        # DataLoader validation\n",
    "        validation_data = TensorDataset(self.validation_inputs, self.validation_masks, self.validation_segment,\n",
    "                                        self.validation_labels)\n",
    "        validation_sampler = SequentialSampler(validation_data)\n",
    "        self.validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "    def instanciate_bert(self, model_name=\"bert-base-uncased\", num_labels=3, output_attentions=False,\n",
    "                         output_hidden_states=False, learning_rate=1e-5, epsilon=1e-8, epoch=2):\n",
    "\n",
    "        self.model = BertForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=num_labels,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "        )\n",
    "        try:\n",
    "            self.model.cuda()\n",
    "        except:\n",
    "            print(\"No cuda GPU available\")\n",
    "\n",
    "        self.optimizer = AdamW(self.model.parameters(),\n",
    "                               lr=learning_rate,\n",
    "                               eps=epsilon\n",
    "                               )\n",
    "\n",
    "        self.epochs = 2\n",
    "        self.total_steps = len(self.train_dataloader) * self.epochs\n",
    "        self.scheduler = get_linear_schedule_with_warmup(self.optimizer,\n",
    "                                                         num_warmup_steps=0,  # Default value in run_glue.py\n",
    "                                                         num_training_steps=self.total_steps)\n",
    "\n",
    "    @staticmethod\n",
    "    def flat_accuracy(predictions, labels):\n",
    "        flat_predictions = np.argmax(predictions, axis=1).flatten()\n",
    "        flat_labels = labels.flatten()\n",
    "        return np.sum(flat_predictions == flat_labels) / len(flat_labels)\n",
    "\n",
    "    @staticmethod\n",
    "    def format_time(elapsed):\n",
    "        \"\"\"\n",
    "        Takes a time in seconds and returns a string hh:mm:ss\n",
    "        \"\"\"\n",
    "        elapsed_rounded = int(round(elapsed))\n",
    "        return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "    def train_model(self, seed_val=44):\n",
    "        random.seed(seed_val)\n",
    "        np.random.seed(seed_val)\n",
    "        torch.manual_seed(seed_val)\n",
    "        torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "        loss_values = []\n",
    "\n",
    "        for epoch_i in range(0, self.epochs):\n",
    "\n",
    "            #  Training\n",
    "            print(f'\\n--------------------- Epoch {epoch_i + 1} / {self.epochs} ---------------------')\n",
    "            print('Training...')\n",
    "            t0 = time.time()\n",
    "            total_loss = 0\n",
    "            self.model.train()\n",
    "\n",
    "            for step, batch in enumerate(self.train_dataloader):\n",
    "                if step % 100 == 0 and not step == 0:\n",
    "                    elapsed = self.format_time(time.time() - t0)\n",
    "                    # Report progress\n",
    "                    print(\n",
    "                        f\"Batch {step}  of  {len(self.train_dataloader)}.    Elapsed: {elapsed}.    Loss: {loss.item()}.\")\n",
    "\n",
    "                batch = tuple(t.to(self.device) for t in batch)\n",
    "                b_input_ids, b_input_mask, b_segment_ids, b_labels = batch\n",
    "\n",
    "                self.model.zero_grad()\n",
    "\n",
    "                # Perform a forward pass (evaluate the model on this training batch).\n",
    "                # return loss\n",
    "                outputs = self.model(b_input_ids,\n",
    "                                     token_type_ids=b_segment_ids,\n",
    "                                     attention_mask=b_input_mask,\n",
    "                                     labels=b_labels)\n",
    "\n",
    "                # all model return tuple -> tuple[0] is loss\n",
    "                loss = outputs[0]\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                # Perform a backward pass to calculate the gradients.\n",
    "                loss.backward()\n",
    "\n",
    "                # Clip the norm of the gradients to 1.0.\n",
    "                # This is to help prevent the \"exploding gradients\" problem.\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "\n",
    "                # Update parameters and take a step using the computed gradient.\n",
    "                self.optimizer.step()\n",
    "                # Update the learning rate.\n",
    "                self.scheduler.step()\n",
    "\n",
    "            # Calculate the average loss over the training data.\n",
    "            avg_train_loss = total_loss / len(self.train_dataloader)\n",
    "\n",
    "            # Store the loss value for plotting the learning curve.\n",
    "            loss_values.append(avg_train_loss)\n",
    "\n",
    "            print(f\"\\n\\tAverage training loss: {avg_train_loss}\")\n",
    "            print(f\"\\tTraining epoch took: {self.format_time(time.time() - t0)}\")\n",
    "\n",
    "            # ----------------Validation-----------------\n",
    "\n",
    "            print(\"Running Validation...\")\n",
    "            t0 = time.time()\n",
    "            self.model.eval()\n",
    "            eval_loss, eval_accuracy = 0, 0\n",
    "            nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "            # Evaluate data for one epoch\n",
    "            for batch in self.validation_dataloader:\n",
    "                batch = tuple(t.to(self.device) for t in batch)\n",
    "                b_input_ids, b_input_mask, b_segment_ids, b_labels = batch\n",
    "\n",
    "                # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
    "                with torch.no_grad():\n",
    "                    # Forward pass, calculate logit predictions.\n",
    "                    # This will return the logits rather than the loss because we have\n",
    "                    # not provided labels.\n",
    "                    outputs = self.model(b_input_ids,\n",
    "                                         token_type_ids=b_segment_ids,\n",
    "                                         attention_mask=b_input_mask)\n",
    "\n",
    "                # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "                # values prior to applying an activation function like softmax.\n",
    "                logits = outputs[0]\n",
    "\n",
    "                # Move logits and labels to CPU\n",
    "                logits = logits.detach().cpu().numpy()\n",
    "                label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "                tmp_eval_accuracy = self.flat_accuracy(logits, label_ids)\n",
    "                eval_accuracy += tmp_eval_accuracy\n",
    "                nb_eval_steps += 1\n",
    "\n",
    "            print(f\"\\tAccuracy: {eval_accuracy / nb_eval_steps}\")\n",
    "            print(f\"\\tValidation took: {self.format_time(time.time() - t0)}\")\n",
    "\n",
    "        print(\"\\nTraining complete!\")\n",
    "\n",
    "    def predict(self, df, max_len=128, batch_size=32):\n",
    "        assert \"sentence_1\" in df.columns.to_list() and \\\n",
    "               \"sentence_2\" in df.columns.to_list(), \\\n",
    "            \"Dataframe should contain columns ['sentence_1','sentence_2']\"\n",
    "\n",
    "        print(f'Number of test sentences: {df.shape[0]}\\n')\n",
    "\n",
    "        input_ids = []\n",
    "        input_ids = list()\n",
    "        for sent1, sent2 in tqdm(zip(df.sentence_1, df.sentence_2)):\n",
    "            input_ids.append(self.tokenizer.encode(sent1, text_pair=sent2, add_special_tokens=True))\n",
    "\n",
    "        input_ids = pad_sequences(input_ids, maxlen=max_len,\n",
    "                                  dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "        df['segment_ids'] = input_ids\n",
    "        df['segment_ids'] = df.input_ids.apply(lambda x: [0] * (x.index(102) + 1) + [1] * (len(x) - (x.index(102) + 1)))\n",
    "        segment_ids = np.array(df.segment_ids)\n",
    "        segment_ids = pad_sequences(segment_ids, maxlen=max_len, dtype=\"long\", value=0, truncating=\"post\",\n",
    "                                    padding=\"post\")\n",
    "\n",
    "        attention_masks = []\n",
    "        for seq in input_ids:\n",
    "            seq_mask = [float(i > 0) for i in seq]\n",
    "            attention_masks.append(seq_mask)\n",
    "\n",
    "        prediction_inputs = torch.tensor(input_ids)\n",
    "        prediction_masks = torch.tensor(attention_masks)\n",
    "        prediction_segment = torch.tensor(segment_ids)\n",
    "        prediction_labels = None\n",
    "\n",
    "        prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_segment)\n",
    "        prediction_sampler = SequentialSampler(prediction_data)\n",
    "        prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
    "\n",
    "        print(f\"Predicting labels for {len(prediction_inputs)} test sentences...\")\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        for batch in prediction_dataloader:\n",
    "            batch = tuple(t.to(self.device) for t in batch)\n",
    "            b_input_ids, b_input_mask, b_segment_ids = batch\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(b_input_ids, token_type_ids=b_segment_ids,\n",
    "                                     attention_mask=b_input_mask)\n",
    "\n",
    "            logits = outputs[0]\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            predictions.append(logits)\n",
    "\n",
    "        print('\\tDONE.')\n",
    "\n",
    "        flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "        self.flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "    def export_prediction_csv(self):\n",
    "        inv_classes = {v: k for k, v in self.classes.items()}\n",
    "        final_result = pd.DataFrame(self.flat_predictions).reset_index().rename(columns={0: \"label\"})\n",
    "        final_result.label = final_result.label.map(inv_classes)\n",
    "        final_result.to_csv(\"final_result.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert = bertTwoSentenceBertClassification(data)\\nbert.predict(df)\\nbert.export_prediction_csv()'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"bert = bertTwoSentenceBertClassification(data)\n",
    "bert.predict(df)\n",
    "bert.export_prediction_csv()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"/kaggle/input/efreiparisdeeplearning2019/dataset_train.csv\", sep='\\t', index_col=0)\n",
    "\n",
    "classes = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "classes = dict(zip(classes, range(len(classes))))\n",
    "data[\"class\"] = data.label.map(classes)\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, SpatialDropout1D, add, concatenate\n",
    "from keras.layers import LSTM, Bidirectional, GRU, Conv1D\n",
    "from keras.layers import GlobalMaxPooling1D, GlobalAveragePooling1D, AveragePooling1D, MaxPooling1D\n",
    "from keras.layers import Dropout, Reshape\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.utils import to_categorical\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "EMBEDDING_FILE = '../input/gensim-embeddings-dataset/glove.840B.300d.gensim'\n",
    "NUM_MODELS = 1\n",
    "BATCH_SIZE = 512\n",
    "DROPOUT = 0.3\n",
    "LSTM_UNITS = 128\n",
    "DENSE_HIDDEN_UNITS = 4 * LSTM_UNITS\n",
    "EPOCHS = 6\n",
    "MAX_LEN_1 = 150\n",
    "MAX_LEN_2 = 70\n",
    "CHARS_TO_REMOVE = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n“”’\\'∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_matrix(word_index, path):\n",
    "    embedding_index = KeyedVectors.load(path, mmap='r')\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "    for word, i in word_index.items():\n",
    "        for candidate in [word, word.lower()]:\n",
    "            if candidate in embedding_index:\n",
    "                embedding_matrix[i] = embedding_index[candidate]\n",
    "                break\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes 25s\n",
    "tokenizer = text.Tokenizer(filters=CHARS_TO_REMOVE, lower=False)\n",
    "tokenizer.fit_on_texts(np.concatenate([data.sentence_1.values, data.sentence_2.values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes 25s\n",
    "sent_1 = tokenizer.texts_to_sequences(data.sentence_1.values)\n",
    "sent_2 = tokenizer.texts_to_sequences(data.sentence_2.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_1 = sequence.pad_sequences(sent_1, maxlen=MAX_LEN_1)\n",
    "sent_2 = sequence.pad_sequences(sent_2, maxlen=MAX_LEN_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_final = np.concatenate([sent_1, sent_2], axis=1)\n",
    "del sent_1, sent_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/gensim-embeddings-dataset/glove.840B.300d.gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-22a26762194d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membedding_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEMBEDDING_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-49-a5b43e193949>\u001b[0m in \u001b[0;36mbuild_matrix\u001b[0;34m(word_index, path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0membedding_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0membedding_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcandidate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname_or_handle, **kwargs)\u001b[0m\n\u001b[1;32m   1538\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWordEmbeddingsKeyedVectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFastTextKeyedVectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'compatible_hash'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname_or_handle, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseKeyedVectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m     \"\"\"\n\u001b[0;32m-> 1381\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1382\u001b[0m         \u001b[0;31m# Because of loading from S3 load can't be used (missing readline in smart_open)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m     )\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, ignore_ext, buffering, encoding, errors)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/gensim-embeddings-dataset/glove.840B.300d.gensim'"
     ]
    }
   ],
   "source": [
    "embedding_matrix = build_matrix(tokenizer.word_index, EMBEDDING_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_labels = to_categorical(data['class'].values, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sent_final, one_hot_labels, test_size=0.1, random_state=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-b95ca619a478>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpatialDropout1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDROPOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM_UNITS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM_UNITS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "words = Input(shape=(None,))\n",
    "x = Embedding(*embedding_matrix.shape, weights=[embedding_matrix], trainable=False)(words)\n",
    "x = SpatialDropout1D(DROPOUT)(x)\n",
    "x = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))(x)\n",
    "x = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))(x)\n",
    "x = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))(x)\n",
    "\n",
    "hidden = concatenate([\n",
    "    GlobalMaxPooling1D()(x),\n",
    "    GlobalAveragePooling1D()(x),\n",
    "])\n",
    "hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])\n",
    "hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])\n",
    "result = Dense(3, activation='sigmoid')(hidden)\n",
    "\n",
    "model = Model(inputs=words, outputs=result)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-93af2fa3f3b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpatialDropout1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDROPOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM_UNITS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstateful\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "words = Input(shape=(None,))\n",
    "x = Embedding(*embedding_matrix.shape, weights=[embedding_matrix], trainable=False)(words)\n",
    "x = SpatialDropout1D(DROPOUT)(x)\n",
    "\n",
    "x = Bidirectional(GRU(LSTM_UNITS, return_sequences=True, stateful=False))(x)\n",
    "x = Bidirectional(GRU(LSTM_UNITS, return_sequences=True, stateful=False))(x)\n",
    "\n",
    "hidden = concatenate([\n",
    "    GlobalAveragePooling1D()(x),\n",
    "    GlobalMaxPooling1D()(x),\n",
    "])\n",
    "\n",
    "hidden = Reshape((BATCH_SIZE, -1))(hidden)\n",
    "\n",
    "hidden = Conv1D(32, 3, strides=1)(hidden)\n",
    "hidden = Dropout(DROPOUT)(hidden)\n",
    "hidden = Conv1D(32, 3, strides=1)(hidden)\n",
    "hidden = Dropout(DROPOUT)(hidden)\n",
    "hidden = MaxPooling1D()(hidden)\n",
    "\n",
    "hidden = Conv1D(64, 3, strides=1)(hidden)\n",
    "hidden = Dropout(DROPOUT)(hidden)\n",
    "hidden = Conv1D(64, 3, strides=1)(hidden)\n",
    "hidden = Dropout(DROPOUT)(hidden)\n",
    "hidden = MaxPooling1D()(hidden)\n",
    "\n",
    "hidden = Conv1D(128, 3, strides=1)(hidden)\n",
    "hidden = Dropout(DROPOUT)(hidden)\n",
    "hidden = Conv1D(128, 3, strides=1)(hidden)\n",
    "hidden = Dropout(DROPOUT)(hidden)\n",
    "hidden = AveragePooling1D()(hidden)\n",
    "\n",
    "hidden = GlobalAveragePooling1D()(hidden)\n",
    "\n",
    "#hidden = Dense(64, activation='relu')(hidden)\n",
    "#hidden = Dense(32, activation='relu')(hidden)\n",
    "result = Dense(3, activation='softmax')(hidden)\n",
    "\n",
    "model = Model(inputs=words, outputs=result)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BertForSequenceClassification' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-265f7af97274>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    583\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 585\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BertForSequenceClassification' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BertForSequenceClassification' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-7381df91a537>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    583\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 585\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BertForSequenceClassification' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "model.predict(x_test, batch_size=2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "max_words = 20\n",
    "max_len = 150\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X_train)\n",
    "sequences = tok.texts_to_sequences(X_train)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from keras.utils import to_categorical\n",
    "one_hot_labels = to_categorical(data['class'].values, num_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sent_final, one_hot_labels, test_size=0.3, random_state=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers import LSTM, GRU, Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras.optimizers as opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_size = 1024\n",
    "n_epochs = 2\n",
    "n_labels = 3\n",
    "n_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(60, output_dim=256))\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(n_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=n_epochs, validation_data=(X_test, y_test))\n",
    "\n",
    "predictions = model.predict(X_test, batch_size=batch_size)\n",
    "\n",
    "test = np.argmax(y_test, axis=1) == np.argmax(predictions, axis=1)\n",
    "\n",
    "len(test[test]) / len(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
